{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/tensorflow/models/tree/master/research/im2txt\n",
    "- https://yashk2810.github.io/\n",
    "- https://github.com/yashk2810/Image-Captioning/blob/master/Image%20Captioning%20InceptionV3.ipynb\n",
    "- https://arxiv.org/pdf/1609.06647.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "import pdb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpath = '/data/image_captioning/flikr8/'\n",
    "img_path = dpath+'Flicker8k_Dataset/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Caption Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, maybe just take the first caption for each image.\n",
    "- construct a regex that matches the first captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create file of only first captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match = '1003163366_44323f5815.jpg#0 '\n",
    "match_2 = '1003163366_44323f5815.jpg#2 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_cap_re = re.compile('^.+\\.jpg#\\d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<_sre.SRE_Match object; span=(0, 27), match='1003163366_44323f5815.jpg#0'>,\n",
       " <_sre.SRE_Match object; span=(0, 27), match='1003163366_44323f5815.jpg#2'>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_cap_re.match(match), first_cap_re.match(match_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_caps_path = dpath+'Flickr8k.token.txt'\n",
    "all_caps = []\n",
    "for line in open(all_caps_path):\n",
    "    if first_cap_re.match(line):\n",
    "        line_arr = line.split('\\t')\n",
    "        img_nm = line_arr[0][:-2]\n",
    "        cap = line_arr[1].strip()\n",
    "        all_caps.append((img_nm, cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40455"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1000268201_693b08cb0e.jpg',\n",
       " 'A little girl climbing into a wooden playhouse .')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_caps[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(all_caps, open(dpath+'all_caps_2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_caps = pickle.load(open(dpath+'all_caps.pkl', 'rb'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train, dev and test captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getImgCapForSet(set_names_path, all_imgs_caps):    \n",
    "    nms = [line.strip() for line in open(set_names_path)]\n",
    "    return [name_cap for name_cap in all_imgs_caps if name_cap[0] in nms] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_nms_caps = getImgCapForSet(dpath+'Flickr_8k.trainImages.txt', all_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,\n",
       " ('1024138940_f1fefbdce1.jpg',\n",
       "  'Two large tan dogs play along a sandy beach .'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_nms_caps), tr_nms_caps[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       " ('1258913059_07c613f7ff.jpg',\n",
       "  'A couple of people sit outdoors at a table with an umbrella and talk .'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nms_caps = getImgCapForSet(dpath+'Flickr_8k.testImages.txt', all_caps)\n",
    "len(test_nms_caps), test_nms_caps[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       " ('1215334959_b1970965f7.jpg', 'A family sits on a bench near a beach .'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_nms_caps = getImgCapForSet(dpath+'Flickr_8k.devImages.txt', all_caps)\n",
    "len(dev_nms_caps), dev_nms_caps[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(tr_nms_caps, open(dpath+'train_all_caps_2.pkl', 'wb'))\n",
    "pickle.dump(test_nms_caps, open(dpath+'test_all_caps_2.pkl', 'wb'))\n",
    "pickle.dump(dev_nms_caps, open(dpath+'dev_all_caps_2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_img_names = [nm.strip() for nm in open(dpath+ 'Flickr_8k.trainImages.txt')]\n",
    "\n",
    "tr_img_path = img_path+'train'\n",
    "for nm in tr_img_names:\n",
    "    os.rename(os.path.join(img_path, nm), os.path.join(tr_img_path, nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def moveImgs(nm_path, out_path, img_path=img_path):\n",
    "    img_names = [nm.strip() for nm in open(nm_path)]\n",
    "    for nm in img_names:\n",
    "        os.rename(os.path.join(img_path, nm), os.path.join(out_path, nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moveImgs(dpath+ 'Flickr_8k.devImages.txt', img_path+'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moveImgs(dpath+ 'Flickr_8k.testImages.txt', img_path+'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp_path =img_path+'samp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_imgs = glob(img_path+'train/wrap/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first32 = tr_imgs[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "next32 = tr_imgs[32:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def copyToPath(fs, p):\n",
    "    for f in fs:\n",
    "        copy(f, os.path.join(p, os.path.basename(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "copyToPath(first32, samp_path+'train/wrap/')\n",
    "copyToPath(next32, samp_path+'val/wrap/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
